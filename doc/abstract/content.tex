\documentclass{amia}
\usepackage{graphicx}
\usepackage[labelfont=bf]{caption}
\usepackage[superscript,nomove]{cite}
\usepackage{color}

\begin{document}

\title{Tailoring Clinical Performance Feedback Using Semantic Technology}
\author{Zach Landis-Lewis, PhD, MLIS$^{1}$, Colin A. Gross$^{1}$, Cooper Stansbury$^{2}$, Dahee Lee$^{1}$, Veena Panicker$^{1}$}
\institutes{
    $^1$University of Michigan, Ann Arbor, MI\\
}

\maketitle

\section*{Background}

Clinical quality dashboards and reports, though ubiquitous in healthcare organizations, are often not useful for improving practice\cite{ivers2012, tuti2017}. Cognitive theories describe two ways in which visual information displays in dashboards and reports can influence clinical practice (i.e. behavior). Firstly, theories describe the cognitive processing of displays for a task (e.g. comparison, trend analysis) and a domain problem (e.g. maintain awareness of my performance relative to peers)\cite{zhang1996, munzner2014}. Secondly, cognitive theories introduce causal pathways through which performance displays can influence practice via mechanisms such as changing motivation and awareness\cite{kluger1996}. These casual pathways commonly depend on situational factors that can change over time, such as the presence of a performance gap between a healthcare professional and a peer-based benchmark. Based on these pathways, the optimal visualization of performance for an individual may differ at any given reporting interval, creating a need to tailor reports for a recipient's situation. 

Knowledge-based systems (KBSs) use explicit representations of knowledge to reason about a set of facts in a domain\cite{neapolitan2018}. A KBS approach to clinical quality reporting could 1) use causal pathways to situationally tailor reports, and 2) to generate data about causal pathway effectiveness for learning to improve report tailoring. The objective of this research is to develop and evaluate a KBS for clinical quality reporting, applied to the clinical domain of obstetric care quality.

%Feedback can significantly impact the professional practice of recipients.
%Giving people appropriate performance feedback is desired for medical professionals.
%The fields of psychology and implementation science offer evidence and theory about acceptable and appropriate performance feedback.
%A single performance feedback template may not be appropriate for all recipients.
%A feedback message make encourage on recipient, but discourage another.
%User centered designe processes collect relevant details about organizations and feedback recipients.
%Visual design best practices inform the creation of attractive and consistent figures.

%\section*{Methods}
\section*{Performance Feedback Tailoring System}

We designed the system as a suite of modular applications that form a software pipeline (Figure 1). The applications in the pipeline depends on the prior development of 3 components: 1) a user-centered report template design and annotation process to develop a report template library, 2) a contextual inquiry process to develop a specification of key characteristics of the setting and recipients of the feedback reports, and 3) a knowledgebase of causal pathways through which performance feedback can influence clinical practice.

%knowledgebase which contains a library of annotated report templates and a set of causal pathways through which performance feedback influences clinical practice.
%process perform data processing and semantic reasoning to select and generate tailored feedback reports for each recipient.

%Here we describe a software pipeline that combines the results of user centered design and visual best practices with data processing and psychological theory to produce feedback tailored for each recipient.
%They are the complimentary computational process to the human centered processes that assess the recipient organization and set the parameters for tailoring feedback.

%The software pipeline begins with the results of user centered design processes;
%a succinct representation of the applicatble psychological theory, figure templates, information about the feedback recipients, and relevant details about the professional environment.
These components provide the configuration that corresponds to the specific professional environment for which the software will tailor feedback.

The pipeline begins with processing of the performance data to make inferences about the attributes of each performer (e.g. a feedback recipient). Annotation functions, written to implement the environment-specific interpretations of attributes, infer attributes of performers from the data. For example, a `performance gap' attribute could be inferred as present when performance is 5 percent or more below average; an `upward trend' is inferred as present when performance values increase by at least .5 over three consecutive time points.
Outputs of the annotation functions are collated into a set of performers with performance-data derived attributes.

Feedback candidates are intermediate constructs generated from attributes of performers and figure templates.
Concatenating the attributes from a performer and a template to produce a feedback candidate provides a computational and conceptual convenience.
It assembles all the attributes that a psychological theory will operate on in a single container.
Template attributes, unlike performer attributes, are known before runtime.
For instance, a template that can display performance from multiple performers would have a peer comparison attribute as will all the candidates generated from this template.
Combining each recipient in turn with each template yields the cartesian product of the sets.

Causal pathways, modeled from theories of performance feedback interventions\cite{kluger1996}, are applied to indicate which candidates are acceptable.
Causal pathways include a set of preconditions which must be present in a candidate in order to assert the candidate is acceptable.
For example, a pathway indicating that peer comparison is more acceptable when there is an upward trend in performance has both "peer comparison" and "upward performance trend" as preconditions.
Applying preconditions of theories in this way results in the set of candidates with attributes added regarding which theories indicate the candidate is acceptable.

Similar preconditions are moderators of psychological theories.
These moderators make indications about the rating of a candidate in relation to other candidates that are acceptable by the same theory. 
Such that, if a theory indicates two candidates are acceptable, it may have a moderator that rates one higher than the other.
To illustrate, a theory may indicate that peer comparison is acceptable and have a moderator that rates a candidate with the positive gap attribute higher than one with negative gap.
Computing the ranks from the moderators adds attributes with values that permit selecting the highest scoring candidate for each theory.

Figures are generated by passing performance data to the functional code of figure templates.
For each performer, the templates from the top scoring candidates of each theory are used.
Multiple theories could agree on a candidate.  
In these cases, only one figure is generated.
In the cases where multiple theories agree on a candidate for a performer, only one figure is generated.
Conversly, multiple figures will be generated for a performer if theories specify different candidates as acceptable and highest scoring.
Using the templates and performance data in this fashion outputs a set of figures for each performer.

The figures generated for each performer can be presented to them for evaluation.
The performer receiving the feedback figures evaluates each for acceptability and appropriateness.
The acceptability and appropriateness of each figure can be attributed back to the theory or theories that selected for generating the figure.
Using figures are proxies for the theories, the recipient scoring can inform a ranking of theories for the environment.
Sufficient replication accross many similar environments can lead to an inter-theory scoring model that permits the selection of a single most appropriate performance feedback for individual recipients.



\section*{Preliminary results}





\makeatletter
\renewcommand{\@biblabel}[1]{\hfill #1.}
\makeatother

\bibliographystyle{unsrt}
\begin{thebibliography}{1}
\setlength\itemsep{-0.1em}

\bibitem{ivers2012}
Ivers N, Jamtvedt G, Flottorp S, Young JM, Odgaard-Jensen J, French SD, et al. Audit and feedback: effects on professional practice and healthcare outcomes. Cochrane Database Syst Rev. 2012;6:CD000259. 
\bibitem{tuti2017}
Tuti T, Nzinga J, Njoroge M, Brown B, Peek N, English M, et al. A systematic review of electronic audit and feedback: intervention effectiveness and use of behaviour change theory. Implementation Science. 2017;12:61.
\bibitem{zhang1996}
Zhang J. A representational analysis of relational information displays. International Journal of Human Computer Studies. 1996;45(1):59-74.
\bibitem{munzner2014}
Munzner T. Visualization Analysis and Design. CRC Press; 2014. 422 p. 
%\bibitem{vessey1991}
%Vessey I. Cognitive fit: A theory-based analysis of the graphs versus tables literature*. Decision Sciences. 1991 Mar 1;22(2):219â€“40.
\bibitem{kluger1996}
Kluger AN, DeNisi A. The effects of feedback interventions on performance: A historical review, a meta-analysis, and a preliminary feedback intervention theory. Psychological Bulletin March 1996. 1996;119(2):254-84.
\bibitem{neapolitan2018}
Neapolitan RE, Jiang X. Artificial Intelligence: With an Introduction to Machine Learning, Second Edition. 2 edition. Chapman and Hall/CRC; 2018. 480 p. 




\end{thebibliography}


\end{document}
